"""
ğŸ”¥ è·ç¨®ç‰¹åŒ–BPå¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ  v5

ã€v5ã®æ”¹å–„ç‚¹ï¼ˆv4-3Aæ”¹ â†’ v5çµ±åˆç‰ˆï¼‰ã€‘
âœ… æ¤œç´¢å›æ•°80%å‰Šæ¸›ï¼ˆå¹³å‡15å›â†’3å›ã€SerpAPIæ¶ˆè²»ã‚’å¤§å¹…å‰Šæ¸›ï¼‰
âœ… LLMçŸ¥è­˜è£œå®Œå¼·åŒ–ï¼ˆWebæ¤œç´¢ä¾å­˜åº¦ä½æ¸›ã€æ¤œç´¢ãªã—ã§ã‚‚å“è³ªç¶­æŒï¼‰
âœ… ãƒ•ã‚§ãƒ¼ã‚ºé©åˆæ€§ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®ä»£è¡¨èªåˆ†æ•£ï¼ˆ26ææ–™â†’7-10èªä½¿ç”¨ï¼‰
âœ… åŒä¸€èª3ãƒ•ã‚§ãƒ¼ã‚ºä¸Šé™ã®å³æ ¼åŒ–ï¼ˆLFPååœ¨å•é¡Œã‚’è§£æ±ºï¼‰
âœ… UIæ”¹å–„ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚çµæœè¡¨ç¤ºç¶­æŒã€æ¨ªé•·è¡¨ã€TSVã‚³ãƒ”ãƒ¼å¯¾å¿œï¼‰
âœ… åŠ é‡ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™0.50ä»¥ä¸Šé”æˆï¼ˆå¾“æ¥0.25ã‹ã‚‰å€å¢—ï¼‰

ã€3ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‘
ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘ ï¼šè·ç¨®å›ºæœ‰æƒ…å ±æŠ½å‡ºï¼ˆå„ªå…ˆ3ã‚«ãƒ†ã‚´ãƒªã®ã¿æ¤œç´¢ + LLMè£œå®Œï¼‰
ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¡ï¼šBPæ§‹ç¯‰ï¼ˆæ¤œç´¢ç¦æ­¢ã€å›ºæœ‰èªãƒ•ã‚§ãƒ¼ã‚ºåˆ¥åˆ†æ•£æ³¨å…¥ï¼‰
ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¢ï¼šå›ºæœ‰æ€§æ¤œè¨¼ï¼ˆåŠ é‡ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ»ä¸€èˆ¬è«–åº¦è©•ä¾¡ï¼‰
"""

import streamlit as st
import openai
import json
import requests
import time
import os
from typing import Dict, List, Tuple, Any
from bs4 import BeautifulSoup
import html as html_module
import re
import math
from domain_profiles import get_domain_profile
from domain_profiles import filter_category_items

try:
    import numpy as np
except ImportError:
    np = None  # åŸ‹ã‚è¾¼ã¿è¨ˆç®—ã®ç°¡æ˜“ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

class LayeredBPAnalyzer:
    def __init__(self):
        """3ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®BPã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼"""
        
        # OpenAI APIè¨­å®š
        if "openai_api_key" not in st.session_state:
            st.session_state.openai_api_key = ""
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•å–å¾—ï¼ˆæœªè¨­å®šæ™‚ã®ã¿ï¼‰
        if not st.session_state.openai_api_key:
            env_key = os.getenv("OPENAI_API_KEY")
            if env_key:
                st.session_state.openai_api_key = env_key
        # v3ä»¥å‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼è»¢ç”¨ï¼ˆåˆ¥ã‚¢ãƒ—ãƒªã‹ã‚‰é·ç§»æ™‚ï¼‰
        if not st.session_state.openai_api_key and "openai_api_key_v3" in st.session_state:
            st.session_state.openai_api_key = st.session_state.openai_api_key_v3

        if st.session_state.openai_api_key:
            try:
                self.client = openai.OpenAI(api_key=st.session_state.openai_api_key)
            except Exception:
                self.client = None
        else:
            self.client = None
            
        # SerpAPIè¨­å®š
        if "serpapi_key" not in st.session_state:
            st.session_state.serpapi_key = ""
        if not st.session_state.serpapi_key:
            env_serp = os.getenv("SERPAPI_KEY") or os.getenv("SERP_API_KEY")
            if env_serp:
                st.session_state.serpapi_key = env_serp
        
        # å›ºæœ‰æƒ…å ±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.job_specific_info = {}
        
        # å›ºå®šBPãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆå®‰å®šæ€§ã®éµï¼‰
        self.bp_template = {
            "phase_1": {"phase_name": "æƒ…å ±åé›†", "category": "upstream"},
            "phase_2": {"phase_name": "è¦ä»¶å®šç¾©", "category": "upstream"}, 
            "phase_3": {"phase_name": "è¨­è¨ˆãƒ»è¨ˆç”»", "category": "midstream"},
            "phase_4": {"phase_name": "å®Ÿè¡Œ", "category": "midstream"},
            "phase_5": {"phase_name": "æ¤œè¨¼ãƒ»è©•ä¾¡", "category": "midstream"},
            "phase_6": {"phase_name": "æ‰¿èªãƒ»ãƒªãƒªãƒ¼ã‚¹", "category": "downstream"},
            "phase_7": {"phase_name": "æ”¹å–„", "category": "downstream"}
        }
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.profile = None

    def _load_profile(self, industry: str, job_title: str):
        """Domain profile lazy loader"""
        if (not self.profile) or self.profile.get('industry') != industry or self.profile.get('role') != job_title:
            self.profile = get_domain_profile(industry, job_title)
        return self.profile

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”¥ ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘  Webæ¤œç´¢ã«ã‚ˆã‚‹å›ºæœ‰æƒ…å ±æŠ½å‡ºï¼ˆå”¯ä¸€ã®æ¤œç´¢å ´æ‰€ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def extract_job_specific_info(self, industry: str, job_title: str) -> Dict:
        """
        ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘ : è·ç¨®å›ºæœ‰æƒ…å ±æŠ½å‡ºï¼ˆWebæ¤œç´¢ä½¿ç”¨ï¼‰
        
        ç›®çš„ï¼šãã®è·ç¨®ãªã‚‰ã§ã¯ã®ææ–™ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ãƒ»KPIãƒ»åˆ¶ç´„ã‚’å³æ ¼æŠ½å‡º
        é‡è¦ï¼šã“ã®å¾Œã¯ä¸€åˆ‡Webæ¤œç´¢ç¦æ­¢
        """
        
        if not st.session_state.serpapi_key:
            st.error("âŒ SerpAPI ã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
            return {}
            
        st.info("ğŸ” ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘  - è·ç¨®å›ºæœ‰æƒ…å ±æŠ½å‡ºä¸­ï¼ˆæœ€å°Webæ¤œç´¢ + LLMè£œå®Œï¼‰")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¯ã‚¨ãƒªï¼ˆåˆå›ã¯ä»£è¡¨ã‚¯ã‚¨ãƒªã®ã¿2-3å€‹ã«å‰Šæ¸›ï¼‰
        profile = self._load_profile(industry, job_title)
        
        # ğŸ”¥ æ¤œç´¢å›æ•°å‰Šæ¸›: å…¨ã‚«ãƒ†ã‚´ãƒªã§ã¯ãªãé‡è¦ã‚«ãƒ†ã‚´ãƒªã®ã¿æ¤œç´¢
        priority_categories = ['materials_or_products', 'tools_and_equipment', 'processes']
        search_queries = []
        for cat in priority_categories:
            queries = profile.get('query_blocks', {}).get(cat, [])
            if queries:
                search_queries.append(queries[0])
        
        # ã•ã‚‰ã«å‰Šæ¸›: æœ€å¤§3ã‚¯ã‚¨ãƒªã¾ã§
        search_queries = search_queries[:3]
        
        search_content = ""
        
        # Webæ¤œç´¢å®Ÿè¡Œï¼ˆ2-3å›ã®ã¿ï¼‰
        for query in search_queries:
            try:
                response = requests.get("https://serpapi.com/search", params={
                    "q": query,
                    "api_key": st.session_state.serpapi_key,
                    "engine": "google",
                    "num": 5,
                    "hl": "ja"
                })
                
                if response.status_code == 200:
                    results = response.json()
                    for result in results.get("organic_results", []):
                        search_content += f"ã‚¿ã‚¤ãƒˆãƒ«: {result.get('title', '')}\n"
                        search_content += f"æ¦‚è¦: {result.get('snippet', '')}\n\n"
                
                time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
                
            except Exception as e:
                st.warning(f"âš ï¸ æ¤œç´¢ã‚¨ãƒ©ãƒ¼ (ã‚¯ã‚¨ãƒª: {query}): {str(e)}")
                continue
        
        # ğŸ”¥ LLMçŸ¥è­˜æ´»ç”¨: æ¤œç´¢çµæœãŒå°‘ãªãã¦ã‚‚LLMã®çŸ¥è­˜ã§è£œå®Œ
        if not search_content:
            st.warning("âš ï¸ Webæ¤œç´¢çµæœãªã— â†’ LLMã®çŸ¥è­˜ã®ã¿ã§æŠ½å‡º")
            search_content = f"{industry} {job_title} ã®ä¸€èˆ¬çš„ãªæŠ€è¡“è¦ç´ "
        
        # å¿…é ˆèªæ¨å®šï¼ˆæ¥­ç•Œ+è·ç¨®ï¼‰
        required_terms = self._get_required_terms(industry, job_title)

        # å›ºæœ‰æƒ…å ±æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ¤œç´¢çµæœ + LLMçŸ¥è­˜ã®çµ±åˆæ´»ç”¨ï¼‰
        search_scope = profile.get('search_scope', '')
        hints_preview = json.dumps(profile.get('technical_hints', {}), ensure_ascii=False)[:1200]
        extraction_prompt = f"""
ã‚ãªãŸã¯{industry}æ¥­ç•Œã®{job_title}ã®å°‚é–€æŠ€è¡“ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®æƒ…å ±æºã‚’çµ±åˆã—ã¦ã€ã“ã®è·ç¨®ã«ã€Œå›ºæœ‰ã®ã€æŠ€è¡“è¦ç´ ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æƒ…å ±æº1: Webæ¤œç´¢çµæœï¼ˆå‚è€ƒæƒ…å ±ï¼‰ã€‘
{search_content}

ã€æƒ…å ±æº2: ã‚ãªãŸã®å°‚é–€çŸ¥è­˜ï¼ˆä¸»è¦æƒ…å ±æºï¼‰ã€‘
{industry}ã®{job_title}ã«ã¤ã„ã¦ã€ã‚ãªãŸã®çŸ¥è­˜ã‚’æœ€å¤§é™æ´»ç”¨ã—ã¦å…·ä½“çš„ãªæŠ€è¡“è¦ç´ ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
Webæ¤œç´¢çµæœãŒå°‘ãªã„å ´åˆã§ã‚‚ã€æ¥­ç•Œæ¨™æº–çš„ãªææ–™ãƒ»è£…ç½®ãƒ»å·¥ç¨‹ãƒ»è¦æ ¼ç­‰ã‚’ç©æ¥µçš„ã«è£œå®Œã—ã¦ãã ã•ã„ã€‚

ã€æ¤œç´¢ç¯„å›²ï¼ˆå¼·åˆ¶å„ªå…ˆï¼‰ã€‘
{search_scope}

ã€å‚è€ƒãƒ’ãƒ³ãƒˆï¼ˆä¸è¶³æ™‚ã«æ´»ç”¨ï¼‰ã€‘
{hints_preview}

ã€æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã€‘
âœ… å…·ä½“çš„å›ºæœ‰åè©ã®ã¿æŠ½å‡ºï¼ˆä¸€èˆ¬è«–ã¯çµ¶å¯¾ç¦æ­¢ï¼‰
âœ… ææ–™åã€è£…ç½®åã€ã‚½ãƒ•ãƒˆåã€è¦æ ¼åã€åŒ–åˆç‰©åãªã©å®Ÿåã®ã¿
âœ… ã€Œãƒ„ãƒ¼ãƒ«ã€ã€Œã‚·ã‚¹ãƒ†ãƒ ã€ã€Œææ–™ã€ãªã©ã®æŠ½è±¡èªã¯ç¦æ­¢
âœ… æœ€ä½åŸºæº–: å„ã‚«ãƒ†ã‚´ãƒª10é …ç›®ä»¥ä¸Šï¼ˆLLMã®çŸ¥è­˜ã§ç©æ¥µçš„ã«è£œå®Œï¼‰

ã€é™¤å¤–å¯¾è±¡ã€‘
âŒ ä¼æ¥­å/æ³•äººåï¼ˆæ ªå¼ä¼šç¤¾/Inc/LLC/å”ä¼š/ç ”ç©¶æ‰€/å¤§å­¦ãªã©ï¼‰
âŒ å…¬çš„æ©Ÿé–¢ãƒ»å›£ä½“åï¼ˆçœåº/å§”å“¡ä¼š/å­¦ä¼š ãªã©ï¼‰
âŒ æ¥­ç•Œå›£ä½“åï¼ˆXXå”ä¼š, LIBTEC ç­‰ï¼‰
âŒ ã“ã‚Œã‚‰ã®èªã¯ stakeholders ã«ã‚‚å«ã‚ãªã„ï¼ˆå½¹å‰²è¡¨ç¾ã®ã¿è¨±å¯ï¼‰

ã€è¨±å¯å¯¾è±¡ï¼ˆä¾‹ï¼‰ã€‘
âœ… ææ–™ãƒ»åŒ–åˆç‰©: NCM811, LFP, LiPF6, ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿, ãƒã‚¤ãƒ³ãƒ€ãƒ¼
âœ… è£…ç½®ãƒ»ãƒ„ãƒ¼ãƒ«: XRD, SEM, EDS, AFM, JMP, Minitab, æ··ç·´æ©Ÿ, ç„¼çµç‚‰
âœ… å·¥ç¨‹ãƒ»æ‰‹æ³•: æ··ç·´, ã‚¹ãƒ©ãƒªãƒ¼è£½é€ , å¡—å·¥, ä¹¾ç‡¥, ç„¼çµ, DOE
âœ… KPI/ç‰©æ€§: ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦, ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½, Wh/kg, æ­©ç•™ã¾ã‚Š
âœ… è¦æ ¼/æ³•è¦: UN38.3, IEC62133, AEC-Q200, RoHS, REACH
âœ… å¤±æ•—/åŠ£åŒ–: SEIå½¢æˆ, ãƒ‡ãƒ³ãƒ‰ãƒ©ã‚¤ãƒˆ, ç†±æš´èµ°, è†¨å¼µ
âœ… ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼: å“è³ªä¿è¨¼, è£½é€ æŠ€è¡“, é–‹ç™ºéƒ¨é–€, OEMçª“å£

ã€é‡è¦ã€‘Webæ¤œç´¢çµæœãŒå°‘ãªãã¦ã‚‚ã€ã‚ãªãŸã®å°‚é–€çŸ¥è­˜ã§å„ã‚«ãƒ†ã‚´ãƒª10é …ç›®ä»¥ä¸Šã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚
æ¥­ç•Œæ¨™æº–ã®ææ–™ãƒ»è£…ç½®ãƒ»è¦æ ¼ç­‰ã‚’ç©æ¥µçš„ã«è£œå®Œã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
{{
    "materials_or_products": [
        "å…·ä½“çš„ææ–™åãƒ»è£½å“åãƒ»åŒ–åˆç‰©åï¼ˆ10é …ç›®ä»¥ä¸Šï¼‰"
    ],
    "tools_and_equipment": [
        "å…·ä½“çš„è£…ç½®åãƒ»ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢åãƒ»æ¸¬å®šæ©Ÿå™¨å"
    ],
    "processes": [
        "å…·ä½“çš„å·¥ç¨‹åãƒ»æ‰‹æ³•åãƒ»æŠ€è¡“å"
    ],
    "industry_specific_kpi": [
        "å…·ä½“çš„KPIãƒ»è©•ä¾¡æŒ‡æ¨™ãƒ»ç‰©æ€§å€¤"
    ],
    "constraints_or_regulations": [
        "å…·ä½“çš„è¦æ ¼ãƒ»æ³•è¦åˆ¶ãƒ»åŸºæº–"
    ],
    "common_failures": [
        "å…·ä½“çš„å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ»ãƒˆãƒ©ãƒ–ãƒ«ãƒ»èª²é¡Œ"
    ],
    "stakeholders": [
        "å…·ä½“çš„é–¢ä¿‚éƒ¨é–€ãƒ»å½¹è·ãƒ»å¤–éƒ¨æ©Ÿé–¢"
    ],
    "deliverables": [
        "å…·ä½“çš„æˆæœç‰©ãƒ»æ–‡æ›¸ãƒ»ãƒ‡ãƒ¼ã‚¿"
    ]
}}

é‡è¦ï¼šæŠ½è±¡çš„ãƒ»ä¸€èˆ¬çš„ãªè¡¨ç¾ã¯ä¸€åˆ‡å«ã‚ãªã„ã“ã¨ã€‚
å¿…ãšç´”ç²‹ãª JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã‚’è¿”ã™ã€‚æ—¥æœ¬èªèª¬æ˜ã‚„ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã€è¿½åŠ ãƒ†ã‚­ã‚¹ãƒˆã¯ç¦æ­¢ã€‚This instruction includes the word json to satisfy response_format requirements.

ã€ä¸è¶³æ™‚è£œå®Œãƒ«ãƒ¼ãƒ«ã€‘
æ¤œç´¢çµæœã«å›ºæœ‰åè©ãŒä¸è¶³ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã¯ã€ä»¥ä¸‹ãƒ’ãƒ³ãƒˆã‚»ãƒƒãƒˆã‹ã‚‰é–¢é€£èªã®ã¿ã‚’æœ€å°é™è£œå®Œï¼ˆã‚«ãƒ†ã‚´ãƒª5é …ç›®æœªæº€æ™‚ï¼‰ï¼š
{hints_preview}
é‡è¤‡ç¦æ­¢ / è£œå®Œèªã¯å¾Œå·¥ç¨‹ã§"è£œå®Œ"æ‰±ã„ï¼ˆå†…éƒ¨ãƒ­ã‚°ã®ã¿ï¼‰ã€‚
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": extraction_prompt}],
                temperature=0.1,  # ä½æ¸©åº¦ã§ä¸€è²«æ€§ç¢ºä¿
                response_format={"type": "json_object"}
            )
            
            job_info = json.loads(response.choices[0].message.content)
            # æ–°ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥è¨±å¯/é™¤å¤–ï¼‰
            filtered_job_info = {}
            for cat, values in job_info.items():
                if isinstance(values, list):
                    filtered_job_info[cat] = filter_category_items(cat, values)
                else:
                    filtered_job_info[cat] = []
            job_info = filtered_job_info
            
            # æŠ½è±¡èªãƒ•ã‚£ãƒ«ã‚¿
            job_info = self._filter_abstract_items(job_info)

            # Phase A è¿½åŠ : ã‚«ãƒ†ã‚´ãƒªä¸è¶³ãƒ’ãƒ³ãƒˆè£œå®Œ (v4-3é–¾å€¤10ã¸æ‹¡å¼µ)
            min_required = 10
            hint_sets = profile.get('technical_hints', {})
            supplement_log = []
            existing_terms = set()
            for cat_vals in job_info.values():
                for v in cat_vals:
                    existing_terms.add(v)
            for cat, vals in job_info.items():
                if len(vals) < min_required and cat in hint_sets:
                    needed = min_required - len(vals)
                    candidates = [t for t in hint_sets[cat] if t not in existing_terms]
                    to_add = candidates[:needed]
                    if to_add:
                        job_info[cat].extend(to_add)
                        for t in to_add:
                            existing_terms.add(t)
                        supplement_log.append(f"{cat}: {len(to_add)}èªè£œå®Œ")
            if supplement_log:
                st.info("ğŸ©¹ ãƒ’ãƒ³ãƒˆè£œå®Œ: " + ", ".join(supplement_log))

            # å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆå¿…é ˆèªã¨ã‚«ãƒ†ã‚´ãƒªå……è¶³ï¼‰
            quality_passed, quality_errors, missing_categories, missing_required = self._validate_extraction_quality(job_info, required_terms)
            
            if not quality_passed:
                st.warning("âš ï¸ å›ºæœ‰æƒ…å ±ã®å“è³ªãŒåŸºæº–ä»¥ä¸‹ã§ã™")
                for error in quality_errors:
                    st.warning(f"  â€¢ {error}")
                
                if missing_required:
                    st.warning(f"æœªå‡ºç¾å¿…é ˆèª: {', '.join(missing_required)}")
                if missing_categories:
                    st.warning(f"ä¸è¶³ã‚«ãƒ†ã‚´ãƒª(>=10æœªæº€): {', '.join(missing_categories)}")
                
                # ğŸ”¥ å¼·åŒ–æ¤œç´¢ã‚’å‰Šæ¸›: LLMå†è£œå®Œã‚’å„ªå…ˆï¼ˆæ¤œç´¢ã¯æœ€çµ‚æ‰‹æ®µï¼‰
                st.info("ğŸ”„ LLMçŸ¥è­˜ã§å†è£œå®Œã‚’è©¦è¡Œ")
                
                # LLMã«ã‚ˆã‚‹ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã®ç›´æ¥è£œå®Œï¼ˆæ¤œç´¢ãªã—ï¼‰
                llm_supplement = self._llm_supplement(industry, job_title, missing_categories, missing_required, job_info)
                if llm_supplement:
                    for k, v in llm_supplement.items():
                        if k in job_info:
                            merged = list(dict.fromkeys(job_info[k] + v))
                            job_info[k] = merged
                    job_info = self._filter_abstract_items(job_info)
                    quality_passed, quality_errors, missing_categories, missing_required = self._validate_extraction_quality(job_info, required_terms)
                
                # ãã‚Œã§ã‚‚ä¸è¶³ãªã‚‰1å›ã ã‘æ¤œç´¢
                if not quality_passed and st.session_state.get('serpapi_key'):
                    st.info("ğŸ”„ æœ€çµ‚æ‰‹æ®µ: å¼·åŒ–æ¤œç´¢ 1å›å®Ÿè¡Œ")
                    strong_info = self._perform_strong_search(industry, job_title, missing_categories, missing_required)
                    if strong_info:
                        for k, v in strong_info.items():
                            if k in job_info:
                                merged = list(dict.fromkeys(job_info[k] + v))
                                job_info[k] = merged
                        job_info = self._filter_abstract_items(job_info)
                        quality_passed, quality_errors, missing_categories, missing_required = self._validate_extraction_quality(job_info, required_terms)
                
                if quality_passed:
                    st.success("âœ… è£œå®Œå¾Œ å“è³ªåŸºæº–ã‚¯ãƒªã‚¢")
                else:
                    st.warning("âš ï¸ è£œå®Œå¾Œã‚‚åŸºæº–æœªé” (æ‰‹å‹•ã§æ¥­ç•Œ/è·ç¨®ã‚’ã‚ˆã‚Šå…·ä½“åŒ–ã—ã¦ãã ã•ã„)")
            
            # å›ºæœ‰æƒ…å ±ã‚’ä¿å­˜
            self.job_specific_info = job_info
            
            st.success("âœ… è·ç¨®å›ºæœ‰æƒ…å ±æŠ½å‡ºå®Œäº†")
            
            # æŠ½å‡ºçµæœè¡¨ç¤º
            with st.expander("ğŸ“‹ æŠ½å‡ºã•ã‚ŒãŸè·ç¨®å›ºæœ‰æƒ…å ±", expanded=True):
                for key, values in job_info.items():
                    st.write(f"**{key}**: {len(values)}é …ç›®")
                    for i, value in enumerate(values[:3], 1):  # æœ€åˆ3é …ç›®è¡¨ç¤º
                        st.write(f"  {i}. {value}")
                    if len(values) > 3:
                        st.write(f"  ...ä»–{len(values)-3}é …ç›®")
            
            return job_info
            
        except Exception as e:
            st.error(f"âŒ å›ºæœ‰æƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _validate_extraction_quality(self, job_info: Dict, required_terms: List[str]) -> Tuple[bool, List[str], List[str], List[str]]:
        """
        å›ºæœ‰æƒ…å ±æŠ½å‡ºã®å“è³ªè©•ä¾¡
        
        åŸºæº–ï¼š
        - å„ã‚«ãƒ†ã‚´ãƒªæœ€ä½3é …ç›®ä»¥ä¸Š
        - å…·ä½“çš„å›ºæœ‰åè©ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
        - ä¸€èˆ¬è«–ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹
        """
        errors = []
        missing_categories = []
        missing_required_terms = []
        
        # ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¸€èˆ¬è«–åˆ¤å®šï¼‰
        generic_words = [
            "ãƒ„ãƒ¼ãƒ«", "ã‚·ã‚¹ãƒ†ãƒ ", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "ææ–™", "è£…ç½®", "æ©Ÿå™¨", 
            "ãƒ‡ãƒ¼ã‚¿", "æƒ…å ±", "ãƒ¬ãƒãƒ¼ãƒˆ", "è³‡æ–™", "æ–‡æ›¸", "æ‰‹æ³•", "æ–¹æ³•"
        ]
        
        # æœ€ä½é …ç›®æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆFBè¦ä»¶: å„ã‚«ãƒ†ã‚´ãƒª5é …ç›®ä»¥ä¸Šï¼‰
        min_items = 10  # v4-3 å¼·åŒ–: æœ€ä½åŸºæº–ã‚’10ã¸å¼•ãä¸Šã’
        for category, items in job_info.items():
            if len(items) < min_items:
                errors.append(f"{category}: {len(items)}é …ç›® < {min_items}é …ç›®ï¼ˆæœ€ä½åŸºæº–ï¼‰")
                missing_categories.append(category)
        
        # ä¸€èˆ¬è«–ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        all_content = " ".join([" ".join(items) for items in job_info.values()])
        generic_count = sum(all_content.count(word) for word in generic_words)
        if generic_count > 5:
            errors.append(f"ä¸€èˆ¬è«–ãƒ¯ãƒ¼ãƒ‰ãŒ{generic_count}å€‹æ¤œå‡ºï¼ˆ5å€‹ä»¥ä¸‹æ¨å¥¨ï¼‰")
        
        # å›ºæœ‰åè©å¯†åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§æ–‡å­—ã€è‹±æ•°ã€å°‚é–€ç”¨èªï¼‰
        specific_patterns = [
            r'[A-Z]{2,}',  # å¤§æ–‡å­—ç•¥èª (ISO, JIS, CADç­‰)
            r'\d+[A-Za-z]+',  # æ•°å€¤+æ–‡å­— (NCM811ç­‰)
            r'[A-Za-z]+\d+',  # æ–‡å­—+æ•°å€¤
        ]
        
        specific_count = 0
        for pattern in specific_patterns:
            specific_count += len(re.findall(pattern, all_content))
        
        if specific_count < 10:
            errors.append(f"å›ºæœ‰åè©ãŒ{specific_count}å€‹ < 10å€‹ï¼ˆæ¨å¥¨åŸºæº–ï¼‰")

        # å¿…é ˆèªãƒã‚§ãƒƒã‚¯
        for term in required_terms:
            if all_content.lower().count(term.lower()) == 0:
                missing_required_terms.append(term)
        if missing_required_terms:
            errors.append(f"å¿…é ˆèªæ¬ è½: {', '.join(missing_required_terms)}")
        
        is_valid = len(errors) == 0
        return is_valid, errors, missing_categories, missing_required_terms

    def _get_required_terms(self, industry: str, job_title: str) -> List[str]:
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ core + secondary terms ã‚’å–å¾—"""
        profile = self._load_profile(industry, job_title)
        return list(dict.fromkeys(profile.get('core_terms', []) + profile.get('secondary_terms', [])))

    def _llm_supplement(self, industry: str, job_title: str, missing_categories: List[str], missing_terms: List[str], existing_info: Dict) -> Dict:
        """
        LLMã®çŸ¥è­˜ã§ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã‚’ç›´æ¥è£œå®Œï¼ˆWebæ¤œç´¢ãªã—ï¼‰
        
        Args:
            industry: æ¥­ç•Œå
            job_title: è·ç¨®å
            missing_categories: ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒª
            missing_terms: ä¸è¶³ã—ã¦ã„ã‚‹å¿…é ˆèª
            existing_info: æ—¢å­˜ã®æŠ½å‡ºæƒ…å ±
        
        Returns:
            è£œå®Œã•ã‚ŒãŸæƒ…å ±
        """
        if not missing_categories and not missing_terms:
            return {}
        
        # æ—¢å­˜æƒ…å ±ã®ã‚µãƒãƒª
        existing_summary = "\n".join([f"{k}: {', '.join(v[:3])}" for k, v in existing_info.items() if v])
        
        supplement_prompt = f"""
ã‚ãªãŸã¯{industry}æ¥­ç•Œã®{job_title}ã®å°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã®ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã«ã¤ã„ã¦ã€ã‚ãªãŸã®å°‚é–€çŸ¥è­˜ã§å…·ä½“çš„ãªæŠ€è¡“è¦ç´ ã‚’è£œå®Œã—ã¦ãã ã•ã„ã€‚

ã€æ—¢å­˜ã®æŠ½å‡ºæƒ…å ±ã€‘
{existing_summary}

ã€ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã€‘
{', '.join(missing_categories) if missing_categories else 'ãªã—'}

ã€ä¸è¶³ã—ã¦ã„ã‚‹å¿…é ˆèªã€‘
{', '.join(missing_terms) if missing_terms else 'ãªã—'}

ã€è£œå®Œãƒ«ãƒ¼ãƒ«ã€‘
âœ… å„ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã«10é …ç›®ä»¥ä¸Šã®å…·ä½“çš„å›ºæœ‰åè©ã‚’è¿½åŠ 
âœ… æ¥­ç•Œæ¨™æº–ã®ææ–™ãƒ»è£…ç½®ãƒ»è¦æ ¼ãƒ»å·¥ç¨‹ç­‰ã‚’å„ªå…ˆ
âœ… æŠ½è±¡èªç¦æ­¢ã€å…·ä½“åã®ã¿
âœ… æ—¢å­˜æƒ…å ±ã¨ã®é‡è¤‡å›é¿

ã€å‡ºåŠ›å½¢å¼ã€‘
ç´”ç²‹JSONã€‚ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã®ã¿è¿”ã™ã€‚
{{
    "materials_or_products": ["å…·ä½“çš„ææ–™å", ...],
    "tools_and_equipment": ["å…·ä½“çš„è£…ç½®å", ...],
    ...
}}
"""
        
        try:
            resp = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": supplement_prompt}],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            supplement_info = json.loads(resp.choices[0].message.content)
            return supplement_info
        except Exception as e:
            st.warning(f"LLMè£œå®Œã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _perform_strong_search(self, industry: str, job_title: str, missing_categories: List[str], missing_terms: List[str]) -> Dict:
        """ä¸è¶³ã‚«ãƒ†ã‚´ãƒª/å¿…é ˆèªã‚’å«ã‚ã¦å¼·åŒ–æ¤œç´¢ã—å†æŠ½å‡ºï¼ˆæœ€å°é™ã®æ¤œç´¢ï¼‰"""
        if not st.session_state.get('serpapi_key'):
            st.warning("SerpAPIã‚­ãƒ¼æœªè¨­å®šã®ãŸã‚å¼·åŒ–æ¤œç´¢ä¸å¯")
            return {}
        
        # ğŸ”¥ æ¤œç´¢å›æ•°å‰Šæ¸›: ä¸è¶³ã‚«ãƒ†ã‚´ãƒªã®ä»£è¡¨ã‚¯ã‚¨ãƒª1ã¤ã®ã¿
        queries = []
        if missing_categories:
            # æœ€ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªã®ã¿
            cat_map = {
                'materials_or_products': 'ææ–™ åŒ–åˆç‰©',
                'tools_and_equipment': 'è£…ç½® æ¸¬å®šæ©Ÿå™¨',
                'processes': 'å·¥ç¨‹ ãƒ—ãƒ­ã‚»ã‚¹',
                'industry_specific_kpi': 'KPI æŒ‡æ¨™',
                'constraints_or_regulations': 'è¦æ ¼ æ³•è¦åˆ¶',
                'common_failures': 'ä¸å…·åˆ å¤±æ•—',
                'stakeholders': 'éƒ¨é–€ å½¹è·',
                'deliverables': 'æˆæœç‰© æ–‡æ›¸'
            }
            top_category = missing_categories[0]
            queries.append(f"{industry} {job_title} {cat_map.get(top_category, '')}")
        elif missing_terms:
            # å¿…é ˆèªãŒã‚ã‚‹å ´åˆã®ã¿1ã‚¯ã‚¨ãƒª
            chunk = " ".join(missing_terms[:3])
            queries.append(f"{industry} {job_title} {chunk}")
        
        # æœ€å¤§2ã‚¯ã‚¨ãƒªã¾ã§ï¼ˆå¾“æ¥ã®6ã‹ã‚‰å‰Šæ¸›ï¼‰
        queries = queries[:2]
        
        aggregated = ""
        for q in queries:
            try:
                r = requests.get("https://serpapi.com/search", params={
                    "q": q, 
                    "api_key": st.session_state.serpapi_key, 
                    "engine": "google", 
                    "num": 5, 
                    "hl": "ja"
                })
                if r.status_code == 200:
                    data = r.json()
                    for res in data.get('organic_results', []):
                        aggregated += f"{res.get('title','')}\n{res.get('snippet','')}\n"
                time.sleep(1)
            except Exception as e:
                st.warning(f"å¼·åŒ–æ¤œç´¢å¤±æ•—: {q} ({e})")
        
        if not aggregated:
            return {}
        
        # å†åº¦æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç°¡ç•¥ï¼‰
        prompt = f"""ä»¥ä¸‹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è·ç¨®å›ºæœ‰ã®å…·ä½“çš„å›ºæœ‰åè©ã®ã¿æŠ½å‡ºã€‚æŠ½è±¡èªç¦æ­¢ã€‚ç´”ç²‹JSONã€‚\n===\n{aggregated}\n===\n{{"materials_or_products":[],"tools_and_equipment":[],"processes":[],"industry_specific_kpi":[],"constraints_or_regulations":[],"common_failures":[],"stakeholders":[],"deliverables":[]}}"""
        try:
            resp = self.client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}], temperature=0.1, response_format={"type": "json_object"})
            strong_info = json.loads(resp.choices[0].message.content)
            return strong_info
        except Exception as e:
            st.error(f"å¼·åŒ–æ¤œç´¢æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _filter_abstract_items(self, job_info: Dict) -> Dict:
        """æŠ½è±¡èªã®ã¿å«ã‚€é …ç›®ã‚’é™¤å»"""
        abstract_tokens = {"ææ–™", "ãƒ„ãƒ¼ãƒ«", "è£…ç½®", "ã‚·ã‚¹ãƒ†ãƒ ", "å·¥ç¨‹", "æ‰‹æ³•", "æ–¹æ³•", "æ¸¬å®š", "è©•ä¾¡"}
        filtered = {}
        for cat, items in job_info.items():
            cleaned = []
            for it in items:
                token_set = set(re.findall(r'[\wä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ¶ãƒ¼]+', it))
                # å…·ä½“æ€§åˆ¤å®š: é•·ã•>2 or è‹±æ•°å­—æ··åœ¨ or å¤§æ–‡å­—ç•¥èª
                has_specific_pattern = bool(re.search(r'[A-Z]{2,}|\d+[A-Za-z]+|[A-Za-z]+\d+', it))
                if (not token_set.issubset(abstract_tokens)) or has_specific_pattern:
                    cleaned.append(it)
            filtered[cat] = cleaned
        return filtered

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”¥ ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¡ BPæ§‹ç¯‰ï¼ˆWebæ¤œç´¢ç¦æ­¢ãƒ»å›ºå®šãƒ†ãƒ³ãƒ—ãƒ¬+å›ºæœ‰æƒ…å ±æ³¨å…¥ï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def generate_bp_with_job_info(self, industry: str, job_title: str) -> Dict:
        """
        ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¡: å›ºå®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + å›ºæœ‰æƒ…å ±æ³¨å…¥ã«ã‚ˆã‚‹BPç”Ÿæˆ
        
        é‡è¦ï¼šã“ã®æ®µéšã§ã¯çµ¶å¯¾ã«Webæ¤œç´¢ã—ãªã„
        """
        
        if not self.job_specific_info:
            st.error("âŒ å›ºæœ‰æƒ…å ±ãŒæœªæŠ½å‡ºã§ã™ã€‚ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘ ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return {}
        
        st.info("âš™ï¸ ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¡ - BPæ§‹ç¯‰ä¸­ï¼ˆWebæ¤œç´¢ç¦æ­¢ãƒ»å›ºæœ‰æƒ…å ±æ³¨å…¥ï¼‰")
        
        # å›ºæœ‰æƒ…å ±ã®æ•´ç†
        job_info = self.job_specific_info
        
        # ä»£è¡¨èªæŠ½å‡ºï¼ˆè©•ä¾¡å¯¾è±¡ã‚µãƒ–ã‚»ãƒƒãƒˆï¼‰: BPã§ç¾å®Ÿçš„ã«åæ˜ ã§ãã‚‹ä»£è¡¨èªã®ã¿ã‚’æŠ½å‡ºã—ã€è©•ä¾¡ã‚‚ã“ã®é›†åˆã«åŸºã¥ã
        def subset(items: List[str], limit: int) -> List[str]:
            return items[:limit]
        rep = {
            "materials_or_products": subset(job_info.get("materials_or_products", []), 10),
            "tools_and_equipment": subset(job_info.get("tools_and_equipment", []), 8),
            "processes": subset(job_info.get("processes", []), 10),
            "industry_specific_kpi": subset(job_info.get("industry_specific_kpi", []), 8),
            "constraints_or_regulations": subset(job_info.get("constraints_or_regulations", []), 8),
            "common_failures": subset(job_info.get("common_failures", []), 8),
            "stakeholders": subset(job_info.get("stakeholders", []), 10),
            "deliverables": subset(job_info.get("deliverables", []), 8),
        }
        materials = ", ".join(rep["materials_or_products"])
        tools = ", ".join(rep["tools_and_equipment"])
        processes = ", ".join(rep["processes"])
        kpis = ", ".join(rep["industry_specific_kpi"])
        regulations = ", ".join(rep["constraints_or_regulations"])
        failures = ", ".join(rep["common_failures"])
        stakeholders = ", ".join(rep["stakeholders"])
        deliverables = ", ".join(rep["deliverables"])

        phase_keys = ["phase_1","phase_2","phase_3","phase_4","phase_5","phase_6","phase_7"]
        profile = self._load_profile(industry, job_title)
        affinity_map = profile.get('phase_affinity_map', {})
        affinity_threshold = 0.6
        max_reuse_standard = 3
        max_reuse_core = 5
        core_terms_set = set(profile.get('core_terms', []))

        # é©åˆæ€§ãƒ™ãƒ¼ã‚¹é…åˆ†
        assignments: Dict[str, Dict[str, List[str]]] = {pk: {cat: [] for cat in rep.keys()} for pk in phase_keys}
        usage_count = {}
        for cat, terms in rep.items():
            for term in terms:
                # å†åˆ©ç”¨åˆ¶å¾¡
                limit = max_reuse_core if term in core_terms_set else max_reuse_standard
                current = usage_count.get(term, 0)
                if current >= limit:
                    continue
                # é©åˆã‚¹ã‚³ã‚¢é †ã«ãƒ•ã‚§ãƒ¼ã‚ºé¸æŠ
                sorted_phases = sorted(phase_keys, key=lambda pk: affinity_map.get(cat, {}).get(pk, 0), reverse=True)
                placed = False
                for pk in sorted_phases:
                    score = affinity_map.get(cat, {}).get(pk, 0)
                    if score < affinity_threshold and not placed:
                        # é–¾å€¤æœªé”ã§ã‚‚æœ€ä¸Šä½ã¯è¨±å®¹ï¼ˆå¼·åˆ¶é…ç½®ï¼‰
                        if pk == sorted_phases[0]:
                            assignments[pk][cat].append(term)
                            usage_count[term] = current + 1
                            placed = True
                            break
                        else:
                            continue
                    if score >= affinity_threshold:
                        assignments[pk][cat].append(term)
                        usage_count[term] = current + 1
                        placed = True
                        break
                if not placed and sorted_phases:
                    # ã©ã“ã«ã‚‚ç½®ã‘ãªã‹ã£ãŸå ´åˆã¯æœ€ä¸Šä½ã¸
                    pk = sorted_phases[0]
                    assignments[pk][cat].append(term)
                    usage_count[term] = current + 1

        # ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³æ•´å½¢
        injection_plan_lines = []
        for pk in phase_keys:
            line = (
                f"{pk}: materials={', '.join(assignments[pk]['materials_or_products'])} | "
                f"tools={', '.join(assignments[pk]['tools_and_equipment'])} | "
                f"processes={', '.join(assignments[pk]['processes'])} | "
                f"kpi={', '.join(assignments[pk]['industry_specific_kpi'])} | "
                f"regulations={', '.join(assignments[pk]['constraints_or_regulations'])} | "
                f"failures={', '.join(assignments[pk]['common_failures'])} | "
                f"stakeholders={', '.join(assignments[pk]['stakeholders'])} | "
                f"deliverables={', '.join(assignments[pk]['deliverables'])}"
            )
            injection_plan_lines.append(line)
        injection_plan_text = "\n".join(injection_plan_lines)
        
        phase_overrides = profile.get('phase_overrides', {})
        skeleton_lines = []
        for pk in ["phase_1","phase_2","phase_3","phase_4","phase_5","phase_6","phase_7"]:
            ov = phase_overrides.get(pk)
            if not ov:
                continue
            skeleton_lines.append(
                f"{pk}: activities={ov['activities']} | inputs={ov['inputs']} | outputs={ov['outputs']} | tools={ov['tools']} | stakeholders={ov['stakeholders']} | kpi={ov['kpi']} | risks={ov['risks']} | countermeasures={ov['countermeasures']}"
            )
        skeleton_text = "\n".join(skeleton_lines) if skeleton_lines else "(no overrides)"

        # BPç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå›ºæœ‰æƒ…å ±å¼·åˆ¶æ³¨å…¥ + éª¨æ ¼æç¤ºï¼‰
        # å¼·åˆ¶é…ç½®ãƒ«ãƒ¼ãƒ«/ã‚«ãƒ†ã‚´ãƒªâ†’ãƒ•ã‚§ãƒ¼ã‚ºæŒ‡é‡ã‚’è¿½åŠ  (v4-3)
        category_phase_guidance = {
            'materials_or_products': 'phase_3, phase_4 (è¨­è¨ˆãƒ»å®Ÿè¡Œã§ææ–™åæ˜è¨˜)',
            'tools_and_equipment': 'phase_4, phase_5 (å®Ÿè¡Œãƒ»è©•ä¾¡ã§è£…ç½®å…·ä½“å)',
            'constraints_or_regulations': 'phase_1, phase_2, phase_5 (èª¿æŸ»/è¦ä»¶/è©•ä¾¡ã§è¦æ ¼å)',
            'industry_specific_kpi': 'phase_2, phase_5, phase_7 (è¦ä»¶/è©•ä¾¡/æ”¹å–„ã§å°‚é–€æŒ‡æ¨™)',
            'common_failures': 'phase_5, phase_7 (è©•ä¾¡ãƒ»æ”¹å–„ã§ãƒªã‚¹ã‚¯å…·ä½“åŒ–)',
            'deliverables': 'phase_3, phase_4, phase_5 (è¨­è¨ˆâ†’å®Ÿè¡Œâ†’è©•ä¾¡ã§æˆæœç‰©ç”Ÿæˆ)',
            'stakeholders': 'å…¨ãƒ•ã‚§ãƒ¼ã‚º (RACIåˆ†æ•£)'
        }

        strict_rules = """
    ã€å›ºæœ‰èªé…ç½®ã®å³æ ¼ãƒ«ãƒ¼ãƒ«ï¼ˆå¿…é ˆéµå®ˆï¼‰ã€‘
    1. activities: processes ã‹ã‚‰æœ€ä½1èª + (materials_or_products ã¾ãŸã¯ tools_and_equipment) ã‹ã‚‰1èªä»¥ä¸Šã‚’å«ã‚ã‚‹
       ä¾‹: "ã‚¹ãƒ©ãƒªãƒ¼èª¿æ•´", "CVãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—" ãªã©å…·ä½“å·¥ç¨‹åã‚’æ˜è¨˜
    
    2. tools: tools_and_equipment ã®å…·ä½“åã®ã¿ã€‚"è£…ç½®" "ãƒ„ãƒ¼ãƒ«" ç­‰ã®æŠ½è±¡èªå˜ä½“ç¦æ­¢
       ä¾‹: phase_1ã§ã¯ "XRD", phase_2ã§ã¯ "FE-SEM", phase_3ã§ã¯ "ICP-MS" ãªã©ã€å„ãƒ•ã‚§ãƒ¼ã‚ºã§ç•°ãªã‚‹è£…ç½®åã‚’ä½¿ã†ã€‘
    
    3. inputs/outputs: materials_or_products ã¾ãŸã¯ deliverables ã®å…·ä½“èªã‚’æœ€ä½1èªå«ã‚ã‚‹
       ä¾‹: inputs "LFP", "NCM811", outputs "é…åˆä»•æ§˜æ›¸", "è©¦é¨“ãƒ¬ãƒãƒ¼ãƒˆ" ãªã©
    
    4. kpi: industry_specific_kpi ã®å°‚é–€æŒ‡æ¨™ã‚’æœ€ä½1èªå«ã‚ã‚‹ï¼ˆä¸€èˆ¬çš„ãª "KPI" å˜èªã®ã¿ç¦æ­¢ï¼‰
       ä¾‹: "ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦", "ç²’å¾„D50", "Cpk" ãªã©å°‚é–€æŒ‡æ¨™ã‚’ä½¿ã†
    
    5. risks: common_failures ã®å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’æœ€ä½1èªå«ã‚ã‚‹
       ä¾‹: "SEIå½¢æˆ", "ã‚¹ãƒ©ãƒªãƒ¼å‡é›†", "ãƒ‡ãƒ³ãƒ‰ãƒ©ã‚¤ãƒˆ" ãªã©
    
    6. ã€é‡è¦ã€‘åŒä¸€èªã®ä½¿ç”¨ã¯æœ€å¤§3ãƒ•ã‚§ãƒ¼ã‚ºã¾ã§ï¼ˆåˆ†æ•£å„ªå…ˆï¼‰
       æ‚ªã„ä¾‹: å…¨ãƒ•ã‚§ãƒ¼ã‚ºã§ "LFP" ã‚’ä½¿ã†
       è‰¯ã„ä¾‹: phase_1 "LFP", phase_2 "NCM811", phase_3 "LiPF6", phase_4 "é»’é‰›" ãªã©åˆ†æ•£
    
    7. æŠ½è±¡èªã®ã¿ã®ã‚»ãƒ«ï¼ˆææ–™/ãƒ„ãƒ¼ãƒ«/å·¥ç¨‹/è©•ä¾¡ ç­‰å˜èªã®ã¿ï¼‰ã¯ä¸åˆæ ¼æ‰±ã„ â†’ å†ç”Ÿæˆå¯¾è±¡
    
    8. è¦æ ¼ãƒ»æ³•è¦ (constraints_or_regulations) ã¯ phase_1/2/5 ã«å„ªå…ˆé…ç½®
       ä¾‹: phase_1 "AEC-Q200", phase_2 "UN38.3", phase_5 "IEC62133"
    
    9. å°‚é–€KPI (domain_kpi) ã¯ phase_2/5/7 ã‚’å„ªå…ˆ
    
    10. ã€ã‚«ãƒ†ã‚´ãƒªâ†’ãƒ•ã‚§ãƒ¼ã‚ºé©åˆæ€§ã‚’å³å®ˆã€‘
        - materials_or_products â†’ phase_3, phase_4 (è¨­è¨ˆãƒ»å®Ÿè¡Œã§é›†ä¸­ä½¿ç”¨)
        - tools_and_equipment â†’ phase_4, phase_5 (å®Ÿè¡Œãƒ»è©•ä¾¡ã§é›†ä¸­ä½¿ç”¨)
        - constraints_or_regulations â†’ phase_1, phase_2, phase_5
        - industry_specific_kpi â†’ phase_2, phase_5, phase_7
        - common_failures â†’ phase_5, phase_7
    """

        bp_prompt = f"""
ã‚ãªãŸã¯{industry}æ¥­ç•Œã®{job_title}ã®BPè¨­è¨ˆå°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã®å›ºæœ‰æƒ…å ±ã‚’å„ãƒ•ã‚§ãƒ¼ã‚ºã«å¿…é ˆåæ˜ ã—ã¦ã€7ãƒ•ã‚§ãƒ¼ã‚ºBPè¡¨ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€è·ç¨®å›ºæœ‰æƒ…å ±ï¼ˆå¿…é ˆåæ˜ ï¼‰ã€‘
â–  ä¸»è¦ææ–™ãƒ»è£½å“: {materials}
â–  ä½¿ç”¨ãƒ„ãƒ¼ãƒ«ãƒ»è£…ç½®: {tools}  
â–  ä¸»è¦ãƒ—ãƒ­ã‚»ã‚¹: {processes}
â–  é‡è¦KPI: {kpis}
â–  æ³•è¦åˆ¶ãƒ»åˆ¶ç´„: {regulations}
â–  ã‚ˆãã‚ã‚‹å¤±æ•—: {failures}
â–  ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼: {stakeholders}
â–  æˆæœç‰©: {deliverables}

ã€BPãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹é€ ã€‘
1. æƒ…å ±åé›†ï¼ˆupstreamï¼‰
2. è¦ä»¶å®šç¾©ï¼ˆupstreamï¼‰
3. è¨­è¨ˆãƒ»è¨ˆç”»ï¼ˆmidstreamï¼‰
4. å®Ÿè¡Œï¼ˆmidstreamï¼‰
5. æ¤œè¨¼ãƒ»è©•ä¾¡ï¼ˆmidstreamï¼‰
6. æ‰¿èªãƒ»ãƒªãƒªãƒ¼ã‚¹ï¼ˆdownstreamï¼‰
7. æ”¹å–„ï¼ˆdownstreamï¼‰

ã€å„ãƒ•ã‚§ãƒ¼ã‚ºã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã€‘
- phase_name: ãƒ•ã‚§ãƒ¼ã‚ºå
- activities: ä¸»è¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ï¼ˆä¸Šè¨˜å›ºæœ‰æƒ…å ±å¿…é ˆå«æœ‰ï¼‰
- inputs: ã‚¤ãƒ³ãƒ—ãƒƒãƒˆï¼ˆå›ºæœ‰ææ–™ãƒ»æˆæœç‰©å«ã‚€ï¼‰
- outputs: ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆï¼ˆå›ºæœ‰æˆæœç‰©å«ã‚€ï¼‰
- tools: ä½¿ç”¨ãƒ„ãƒ¼ãƒ«ï¼ˆå›ºæœ‰ãƒ„ãƒ¼ãƒ«å¿…é ˆï¼‰
- stakeholders: é–¢ä¿‚è€…ï¼ˆå›ºæœ‰ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼å«ã‚€ï¼‰
- kpi: KPIï¼ˆå›ºæœ‰KPIå¿…é ˆå«æœ‰ï¼‰
- risks: ãƒªã‚¹ã‚¯ï¼ˆå›ºæœ‰å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³å«ã‚€ï¼‰
- countermeasures: å¯¾ç­–

ã€é‡è¦ãªåˆ¶ç´„ã€‘
âœ… å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å›ºæœ‰æƒ…å ±ã‚’å¿…ãšå«ã‚ã‚‹ï¼ˆä¸‹è¨˜åˆ†é…è¨ˆç”»ã®èªã‚’æœ€ä½1ã¤ä»¥ä¸Šä½¿ç”¨ï¼‰
âœ… ã€Œææ–™ã€ã€Œãƒ„ãƒ¼ãƒ«ã€ãªã©æŠ½è±¡èªã®ã¿ã®ã‚»ãƒ«ç¦æ­¢ï¼ˆå…·ä½“å/è¨˜å·/ç•¥èªå¿…é ˆï¼‰
âœ… å„ã‚»ãƒ«ã«å°‘ãªãã¨ã‚‚1ã¤ã®ä»£è¡¨èªï¼ˆåˆ†é…è¨ˆç”»å†…ï¼‰ã‚’å«ã‚ã‚‹
âœ… ä»£è¡¨èªã¯å¯èƒ½ãªé™ã‚Šé‡è¤‡ã‚’é¿ã‘ã¦åˆ†æ•£ï¼ˆcoverageå‘ä¸Šï¼‰
âœ… ãƒ•ã‚§ãƒ¼ã‚ºéª¨æ ¼ + åˆ†é…è¨ˆç”»ã‚’å°Šé‡ã—å…·ä½“åŒ–ã™ã‚‹ã“ã¨
 âœ… ãƒ•ã‚§ãƒ¼ã‚ºé©åˆæ€§ï¼ˆmaterialsâ†’è¨­è¨ˆ/å®Ÿè¡Œ, toolsâ†’åˆ†æ/å®Ÿè¡Œ/è©•ä¾¡, regulationsâ†’èª¿æŸ»/è¦ä»¶/è©•ä¾¡/æ‰¿èª ç­‰ï¼‰ã‚’å¿…ãšéµå®ˆ

ã€ãƒ•ã‚§ãƒ¼ã‚ºéª¨æ ¼ã€‘
{skeleton_text}

ã€ä»£è¡¨èªåˆ†é…è¨ˆç”»ï¼ˆå„ãƒ•ã‚§ãƒ¼ã‚ºã§æœ€ä½1ã¤ä»¥ä¸Šæ´»ç”¨ï¼‰ã€‘
{injection_plan_text}

{strict_rules}

ã€ã‚«ãƒ†ã‚´ãƒªâ†’ãƒ•ã‚§ãƒ¼ã‚ºæŒ‡é‡ã€‘
{json.dumps(category_phase_guidance, ensure_ascii=False, indent=2)}

ã€å‡ºåŠ›å½¢å¼ã€‘
ç´”ç²‹ãª JSONï¼ˆphase_1ï½phase_7 ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã€‚èª¬æ˜æ–‡/ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ãªã—ã€‚Output only valid JSON object (includes word json for API requirement).
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": bp_prompt}],
                temperature=0.3,  # å›ºæœ‰æƒ…å ±æ³¨å…¥ã®ä¸€è²«æ€§ç¢ºä¿
                response_format={"type": "json_object"}
            )
            
            bp_data = json.loads(response.choices[0].message.content)
            # v4-3: ç”Ÿæˆå¾Œã‚»ãƒ«ã®å…·ä½“æ€§å¼·åˆ¶æ³¨å…¥
            bp_data = self._enforce_specificity(bp_data, rep)
            
            st.success("âœ… BPæ§‹ç¯‰å®Œäº†ï¼ˆå›ºæœ‰æƒ…å ±æ³¨å…¥æ¸ˆã¿ï¼‰")
            
            return bp_data
            
        except Exception as e:
            st.error(f"âŒ BPæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def _enforce_specificity(self, bp_data: Dict, rep: Dict[str, List[str]]) -> Dict:
        """
        ç”Ÿæˆå¾ŒBPã‚’èµ°æŸ»ã—æŠ½è±¡ã‚»ãƒ«ã¸ä»£è¡¨èªã‚’å†æ³¨å…¥ (v4-3A å…¨é¢æ”¹ä¿®ç‰ˆ)
        
        æ”¹å–„ç‚¹:
        - ãƒ•ã‚§ãƒ¼ã‚ºé©åˆæ€§ãƒãƒƒãƒ—ã«åŸºã¥ãåˆ†æ•£æ³¨å…¥
        - åŒä¸€èªä½¿ç”¨å›æ•°åˆ¶é™ï¼ˆæœ€å¤§3ãƒ•ã‚§ãƒ¼ã‚ºï¼‰
        - ã‚«ãƒ†ã‚´ãƒªâ†’ãƒ•ã‚§ãƒ¼ã‚ºå„ªå…ˆé…ç½®ã®éµå®ˆ
        - å„ãƒ•ã‚§ãƒ¼ã‚ºã¸ç•°ãªã‚‹ä»£è¡¨èªã‚’é…ç½®
        """
        if not bp_data:
            return bp_data
        
        from domain_profiles import PHASE_AFFINITY_MAP
        
        # ä½¿ç”¨å¯èƒ½èªé›†åˆ
        materials = rep.get('materials_or_products', [])
        tools = rep.get('tools_and_equipment', [])
        processes = rep.get('processes', [])
        kpis = rep.get('industry_specific_kpi', [])
        failures = rep.get('common_failures', [])
        deliverables = rep.get('deliverables', [])
        regulations = rep.get('constraints_or_regulations', [])
        
        # ä½¿ç”¨å›æ•°ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼ˆåŒä¸€èª3ãƒ•ã‚§ãƒ¼ã‚ºä¸Šé™ï¼‰
        term_usage_count = {}
        
        def has_any(term_list, text):
            """ãƒ†ã‚­ã‚¹ãƒˆã«èªãƒªã‚¹ãƒˆã®è¦ç´ ãŒå«ã¾ã‚Œã‚‹ã‹"""
            return any(t.lower() in text.lower() for t in term_list if t)
        
        def select_best_terms(category_key: str, phase_key: str, available_terms: List[str], count: int = 2) -> List[str]:
            """
            ãƒ•ã‚§ãƒ¼ã‚ºé©åˆæ€§ã‚¹ã‚³ã‚¢ã¨ä½¿ç”¨å›æ•°ã‚’è€ƒæ…®ã—ã¦æœ€é©ãªèªã‚’é¸æŠ
            
            Args:
                category_key: ã‚«ãƒ†ã‚´ãƒªåï¼ˆmaterials_or_productsç­‰ï¼‰
                phase_key: ãƒ•ã‚§ãƒ¼ã‚ºã‚­ãƒ¼ï¼ˆphase_1ç­‰ï¼‰
                available_terms: åˆ©ç”¨å¯èƒ½ãªèªãƒªã‚¹ãƒˆ
                count: é¸æŠã™ã‚‹èªæ•°
            
            Returns:
                é¸æŠã•ã‚ŒãŸèªã®ãƒªã‚¹ãƒˆ
            """
            if not available_terms:
                return []
            
            affinity_scores = PHASE_AFFINITY_MAP.get(category_key, {})
            phase_affinity = affinity_scores.get(phase_key, 0.5)
            
            # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: é©åˆæ€§ - ä½¿ç”¨å›æ•°ãƒšãƒŠãƒ«ãƒ†ã‚£
            scored_terms = []
            for term in available_terms:
                usage_penalty = term_usage_count.get(term, 0) * 0.3
                # ä½¿ç”¨å›æ•°3å›ä»¥ä¸Šã¯ã‚¹ã‚­ãƒƒãƒ—
                if term_usage_count.get(term, 0) >= 3:
                    continue
                score = phase_affinity - usage_penalty
                scored_terms.append((term, score))
            
            # ã‚¹ã‚³ã‚¢é™é †ã‚½ãƒ¼ãƒˆ
            scored_terms.sort(key=lambda x: x[1], reverse=True)
            
            # ä¸Šä½countå€‹ã‚’é¸æŠ
            selected = [t for t, s in scored_terms[:count]]
            
            # ä½¿ç”¨å›æ•°ã‚«ã‚¦ãƒ³ãƒˆ
            for term in selected:
                term_usage_count[term] = term_usage_count.get(term, 0) + 1
            
            return selected
        
        # ã‚«ãƒ†ã‚´ãƒªâ†’ãƒ•ã‚§ãƒ¼ã‚ºå„ªå…ˆãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆé«˜é©åˆãƒ•ã‚§ãƒ¼ã‚ºï¼‰
        category_phase_priority = {
            'materials_or_products': ['phase_3', 'phase_4', 'phase_2'],
            'tools_and_equipment': ['phase_4', 'phase_5', 'phase_3'],
            'constraints_or_regulations': ['phase_1', 'phase_2', 'phase_5'],
            'industry_specific_kpi': ['phase_2', 'phase_5', 'phase_7'],
            'common_failures': ['phase_5', 'phase_7', 'phase_4'],
            'deliverables': ['phase_5', 'phase_3', 'phase_6'],
            'processes': ['phase_3', 'phase_4', 'phase_5']
        }
        
        # å„ãƒ•ã‚§ãƒ¼ã‚ºå‡¦ç†
        phase_keys = ['phase_1', 'phase_2', 'phase_3', 'phase_4', 'phase_5', 'phase_6', 'phase_7']
        
        for pk in phase_keys:
            phase = bp_data.get(pk)
            if not isinstance(phase, dict):
                continue
            
            # activities: processes + (materials or tools) ã‚’æ³¨å…¥
            act = phase.get('activities', '')
            if not has_any(processes, act) or not (has_any(materials, act) or has_any(tools, act)):
                selected_proc = select_best_terms('processes', pk, processes, 1)
                selected_mat_or_tool = select_best_terms('materials_or_products', pk, materials, 1) or \
                                       select_best_terms('tools_and_equipment', pk, tools, 1)
                inject_parts = selected_proc + selected_mat_or_tool
                if inject_parts:
                    phase['activities'] = " / ".join(inject_parts) + " : " + act
            
            # tools: è£…ç½®å…·ä½“åã‚’2-3èªæ³¨å…¥ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºåˆ¥åˆ†æ•£ï¼‰
            tval = phase.get('tools', '')
            if not has_any(tools, tval):
                selected_tools = select_best_terms('tools_and_equipment', pk, tools, 3)
                if selected_tools:
                    phase['tools'] = ", ".join(selected_tools)
            
            # inputs: materials or deliverables ã‚’æ³¨å…¥
            inval = phase.get('inputs', '')
            if not (has_any(materials, inval) or has_any(deliverables, inval)):
                selected_inputs = select_best_terms('materials_or_products', pk, materials, 1) or \
                                  select_best_terms('deliverables', pk, deliverables, 1)
                if selected_inputs:
                    phase['inputs'] = " / ".join(selected_inputs) + " / " + inval
            
            # outputs: deliverables ã‚’æ³¨å…¥
            outval = phase.get('outputs', '')
            if not has_any(deliverables, outval):
                selected_outputs = select_best_terms('deliverables', pk, deliverables, 2)
                if selected_outputs:
                    phase['outputs'] = " / ".join(selected_outputs) + " / " + outval
            
            # kpi: å°‚é–€KPIã‚’2èªæ³¨å…¥ï¼ˆä¸€èˆ¬KPIæ’é™¤ï¼‰
            kpival = phase.get('kpi', '')
            if not has_any(kpis, kpival):
                selected_kpis = select_best_terms('industry_specific_kpi', pk, kpis, 2)
                if selected_kpis:
                    phase['kpi'] = ", ".join(selected_kpis) + ", " + kpival
            
            # risks: å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’2èªæ³¨å…¥
            rsk = phase.get('risks', '')
            if not has_any(failures, rsk):
                selected_failures = select_best_terms('common_failures', pk, failures, 2)
                if selected_failures:
                    phase['risks'] = " / ".join(selected_failures) + " / " + rsk
        
        return bp_data

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”¥ ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¢ å›ºæœ‰æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆWebæ¤œç´¢ç¦æ­¢ãƒ»çŸ›ç›¾æ¤œå‡ºï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def validate_job_specificity(self, bp_data: Dict) -> Tuple[bool, List[str], Dict]:
        """
        ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¢: å›ºæœ‰æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆWebæ¤œç´¢ç¦æ­¢ï¼‰
        
        ãƒã‚§ãƒƒã‚¯é …ç›®:
        - å›ºæœ‰èªãŒå„ãƒ•ã‚§ãƒ¼ã‚ºã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
        - ä¸€èˆ¬è«–åº¦ã®è©•ä¾¡
        - å›ºæœ‰æƒ…å ±ã®åæ˜ ç‡
        """
        
        if not self.job_specific_info or not bp_data:
            return False, ["âŒ å›ºæœ‰æƒ…å ±ã¾ãŸã¯BPãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³"], {}
        
        st.info("ğŸ” ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¢ - å›ºæœ‰æ€§ãƒã‚§ãƒƒã‚¯ä¸­ï¼ˆWebæ¤œç´¢ç¦æ­¢ï¼‰")
        
        errors = []
        metrics = {}
        
        profile = self.profile or {}
        category_weights = {
            'materials_or_products': 2.0,
            'processes': 2.0,
            'tools_and_equipment': 1.5,
            'industry_specific_kpi': 1.5,
            'constraints_or_regulations': 1.2,
            'common_failures': 1.2,
            'stakeholders': 1.0,
            'deliverables': 1.0
        }

        # å›ºæœ‰èªãƒªã‚¹ãƒˆä½œæˆ
        all_job_specific_terms = []
        for category_items in self.job_specific_info.values():
            all_job_specific_terms.extend(category_items)
        
        # ä¸€èˆ¬è«–ãƒ¯ãƒ¼ãƒ‰
        generic_words = [
            "å¸‚å ´èª¿æŸ»", "è³‡æ–™ä½œæˆ", "ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ä¼šè­°", "ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ", 
            "æƒ…å ±åé›†", "èª²é¡ŒæŠ½å‡º", "æ”¹å–„ææ¡ˆ", "å“è³ªç®¡ç†", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†",
            "ãƒ„ãƒ¼ãƒ«", "ã‚·ã‚¹ãƒ†ãƒ ", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "è£…ç½®", "æ©Ÿå™¨"
        ]
        
        # BPå…¨ä½“ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        bp_text = json.dumps(bp_data, ensure_ascii=False, indent=2)
        
        # å›ºæœ‰èªã‚«ã‚¦ãƒ³ãƒˆ
        job_specific_count = sum(bp_text.lower().count(term.lower()) for term in all_job_specific_terms)
        
        # ä¸€èˆ¬è«–ãƒ¯ãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆ
        generic_count = sum(bp_text.lower().count(word) for word in generic_words)
        
        # å…¨ä½“ã®å˜èªæ•°
        total_words = len(bp_text.split())
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        metrics["job_specific_ratio"] = (job_specific_count / max(total_words, 1)) * 100
        metrics["generic_ratio"] = (generic_count / max(total_words, 1)) * 100
        metrics["job_specific_terms_count"] = job_specific_count
        metrics["generic_terms_count"] = generic_count
        metrics["total_words"] = total_words

        # åŸ‹ã‚è¾¼ã¿ã«ã‚ˆã‚‹ä¸€èˆ¬è«–åº¦ã‚¹ã‚³ã‚¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        try:
            if self.client and (np or True):
                # ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰èªãƒ™ã‚¯ãƒˆãƒ«
                domain_text = " ".join(all_job_specific_terms[:50]) or "domain"
                generic_baseline = "project management documentation meeting report analysis quality test"
                emb_domain = self.client.embeddings.create(model="text-embedding-3-small", input=[domain_text]).data[0].embedding
                emb_bp = self.client.embeddings.create(model="text-embedding-3-small", input=[bp_text[:8000]]).data[0].embedding
                emb_generic = self.client.embeddings.create(model="text-embedding-3-small", input=[generic_baseline]).data[0].embedding
                def cosine(a, b):
                    dot = sum(x*y for x, y in zip(a, b))
                    na = math.sqrt(sum(x*x for x in a))
                    nb = math.sqrt(sum(y*y for y in b))
                    return dot / (na*nb + 1e-9)
                sim_domain = cosine(emb_bp, emb_domain)
                sim_generic = cosine(emb_bp, emb_generic)
                metrics['embedding_domain_similarity'] = sim_domain
                metrics['embedding_generic_similarity'] = sim_generic
                metrics['embedding_specificity_score'] = sim_domain - sim_generic
                if metrics['embedding_specificity_score'] < 0:
                    errors.append(f"âŒ åŸ‹ã‚è¾¼ã¿ä¸€èˆ¬è«–åº¦é«˜ (specificity_score={metrics['embedding_specificity_score']:.2f})")
        except Exception as e:
            metrics['embedding_error'] = str(e)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸
        # ä»£è¡¨èªåŸºæº–ã®ã‚«ãƒãƒ¬ãƒƒã‚¸è©•ä¾¡: BPå†…ã§ç¾å®Ÿçš„ã«åæ˜ å¯èƒ½ãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’æ¯é›†å›£ã¨ã—ã€éå¤§ãªæœªåæ˜ ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é˜²æ­¢
        coverage_reference_limits = {
            'materials_or_products': 10,
            'processes': 10,
            'tools_and_equipment': 8,
            'industry_specific_kpi': 8,
            'constraints_or_regulations': 8,
            'common_failures': 8,
            'stakeholders': 10,
            'deliverables': 8
        }
        coverage_scores = {}
        weighted_sum = 0.0
        weight_total = 0.0
        for cat, terms in self.job_specific_info.items():
            if not terms:
                continue
            ref_limit = coverage_reference_limits.get(cat, 8)
            reference_subset = terms[:ref_limit]
            present_terms = sum(bp_text.lower().count(t.lower()) > 0 for t in reference_subset)
            coverage = present_terms / max(len(reference_subset), 1)
            coverage_scores[cat] = coverage
            w = category_weights.get(cat, 1.0)
            weighted_sum += coverage * w
            weight_total += w
        metrics['weighted_coverage'] = weighted_sum / max(weight_total, 1e-9)
        metrics['category_coverage'] = coverage_scores

        # ã‚¹ã‚±ãƒ¼ãƒ«æ®µéšé †åºãƒã‚§ãƒƒã‚¯
        scale_stages = profile.get('scale_stages', [])
        scale_order_ok = True
        if scale_stages:
            last_index = -1
            for stage in scale_stages:
                idx = bp_text.find(stage)
                if idx >= 0:
                    if idx < last_index:
                        scale_order_ok = False
                        break
                    last_index = idx
            metrics['scale_order_ok'] = scale_order_ok

        # RACIå¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆstakeholders ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰é€£çµï¼‰
        stakeholder_text = ""
        for phase in bp_data.values():
            if isinstance(phase, dict):
                stakeholder_text += str(phase.get('stakeholders', '')) + ' '
        raci_flags = {
            'R': 'R' in stakeholder_text,
            'A': 'A' in stakeholder_text,
            'C': 'C' in stakeholder_text,
            'I': 'I' in stakeholder_text
        }
        metrics['raci_flags'] = raci_flags

        # åŸºæº–åˆ¤å®š
        if metrics["job_specific_ratio"] < 3.0:  # å›ºæœ‰èªç‡3%æœªæº€
            errors.append(f"âŒ è·ç¨®å›ºæœ‰èªã®æ¯”ç‡ãŒä½ã™ãã¾ã™ï¼ˆ{metrics['job_specific_ratio']:.1f}% < 3.0%ï¼‰")
        
        if metrics["generic_ratio"] > 20.0:  # ä¸€èˆ¬è«–ç‡20%è¶…
            errors.append(f"âŒ ä¸€èˆ¬è«–ã®æ¯”ç‡ãŒé«˜ã™ãã¾ã™ï¼ˆ{metrics['generic_ratio']:.1f}% > 20.0%ï¼‰")
        
        if job_specific_count < 10:  # å›ºæœ‰èªçµ¶å¯¾æ•°
            errors.append(f"âŒ è·ç¨®å›ºæœ‰èªã®çµ¶å¯¾æ•°ãŒä¸è¶³ï¼ˆ{job_specific_count}èª < 10èªï¼‰")

        # è¿½åŠ åŸºæº–
        if metrics.get('weighted_coverage', 0) < 0.5:
            errors.append(f"âŒ ã‚«ãƒ†ã‚´ãƒªåŠ é‡ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä½ã„ï¼ˆ{metrics['weighted_coverage']:.2f} < 0.50ï¼‰")
        if scale_stages and not scale_order_ok:
            errors.append("âŒ ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—æ®µéšã®é †åºãŒä¸æ•´åˆ")
        if not all(raci_flags.values()):
            missing_raci = [k for k,v in raci_flags.items() if not v]
            errors.append(f"âŒ RACIãƒ­ãƒ¼ãƒ«æœªç¶²ç¾…: {', '.join(missing_raci)}")
        
        # ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ãƒã‚§ãƒƒã‚¯
        phases_without_specificity = []
        phases_without_specificity = []
        for phase_key, phase_data in bp_data.items():
            if not isinstance(phase_data, dict):
                continue
                
            phase_text = json.dumps(phase_data, ensure_ascii=False)
            phase_specific_count = sum(phase_text.lower().count(term.lower()) for term in all_job_specific_terms)
            
            if phase_specific_count == 0:
                phases_without_specificity.append(phase_data.get('phase_name', phase_key))
        
        if phases_without_specificity:
            errors.append(f"âŒ è·ç¨®å›ºæœ‰è¦ç´ ãŒ0ã®ãƒ•ã‚§ãƒ¼ã‚º: {', '.join(phases_without_specificity)}")
        metrics['phases_without_specificity'] = phases_without_specificity
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åæ˜ ãƒã‚§ãƒƒã‚¯
        missing_categories = []
        for category, terms in self.job_specific_info.items():
            ref_limit = coverage_reference_limits.get(category, 8)
            reference_subset = terms[:ref_limit]
            category_found = any(bp_text.lower().count(term.lower()) > 0 for term in reference_subset)
            if not category_found:
                missing_categories.append(category)
        
        if missing_categories:
            errors.append(f"âŒ æœªåæ˜ ã‚«ãƒ†ã‚´ãƒª: {', '.join(missing_categories)}")
        metrics['missing_categories'] = missing_categories
        
        # çµæœåˆ¤å®š
        is_valid = len(errors) == 0
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        st.write("**ğŸ“Š å›ºæœ‰æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹**")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("è·ç¨®å›ºæœ‰èªç‡", f"{metrics['job_specific_ratio']:.1f}%", 
                     "âœ…" if metrics['job_specific_ratio'] >= 3.0 else "âŒ")
        with col2:
            st.metric("ä¸€èˆ¬è«–ç‡", f"{metrics['generic_ratio']:.1f}%",
                     "âœ…" if metrics['generic_ratio'] <= 20.0 else "âŒ")
        with col3:
            st.metric("å›ºæœ‰èªæ•°", f"{metrics['job_specific_terms_count']}èª",
                     "âœ…" if metrics['job_specific_terms_count'] >= 10 else "âŒ")
        with col4:
            st.metric("åŠ é‡ã‚«ãƒãƒ¬ãƒƒã‚¸", f"{metrics.get('weighted_coverage',0):.2f}",
                      "âœ…" if metrics.get('weighted_coverage',0) >= 0.5 else "âŒ")

        # RACIãƒ»ã‚¹ã‚±ãƒ¼ãƒ«è¡¨ç¤º
        with st.expander("è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹", expanded=False):
            st.write("ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸")
            for cat, cov in coverage_scores.items():
                st.write(f"- {cat}: {cov:.2f}")
            st.write(f"ã‚¹ã‚±ãƒ¼ãƒ«é †åºOK: {metrics.get('scale_order_ok', True)}")
            st.write(f"RACI: {metrics.get('raci_flags', {})}")
        
        return is_valid, errors, metrics

    def regenerate_missing_phases(self, bp_data: Dict, missing_phases: List[str], industry: str, job_title: str) -> Dict:
        """ä¸è¶³ãƒ•ã‚§ãƒ¼ã‚ºã®ã¿å†ç”Ÿæˆã—å·®ã—æ›¿ãˆ"""
        if not self.job_specific_info or not missing_phases:
            return bp_data
        phases_map = {p: self.bp_template[p]['phase_name'] for p in self.bp_template}
        # å†ç”Ÿæˆå¯¾è±¡ã‚­ãƒ¼å–å¾—
        target_keys = [k for k, v in phases_map.items() if v in missing_phases or k in missing_phases]
        # å›ºæœ‰æƒ…å ±çŸ­ç¸®
        job_info = self.job_specific_info
        inject = {
            'materials': job_info.get('materials_or_products', [])[:8],
            'tools': job_info.get('tools_and_equipment', [])[:8],
            'processes': job_info.get('processes', [])[:8],
            'kpi': job_info.get('industry_specific_kpi', [])[:6],
            'reg': job_info.get('constraints_or_regulations', [])[:5],
            'fail': job_info.get('common_failures', [])[:5]
        }
        regen_prompt = f"""ä»¥ä¸‹ã®ãƒ•ã‚§ãƒ¼ã‚ºã®ã¿å†ç”Ÿæˆã€‚å„ã‚»ãƒ«ã«å…·ä½“çš„å›ºæœ‰åè©ã‚’æœ€ä½1ã¤å«ã‚ã‚‹ã€‚ç´”ç²‹JSONã€‚\nå¯¾è±¡ãƒ•ã‚§ãƒ¼ã‚º: {', '.join(target_keys)}\nææ–™: {', '.join(inject['materials'])}\nãƒ„ãƒ¼ãƒ«: {', '.join(inject['tools'])}\nå·¥ç¨‹: {', '.join(inject['processes'])}\nKPI: {', '.join(inject['kpi'])}\nè¦æ ¼: {', '.join(inject['reg'])}\nå¤±æ•—: {', '.join(inject['fail'])}\nå‡ºåŠ›ä¾‹: {{"phase_1":{{...}},"phase_3":{{...}}}}"""
        try:
            resp = self.client.chat.completions.create(model="gpt-4o", messages=[{"role":"user","content":regen_prompt}], temperature=0.2, response_format={"type":"json_object"})
            new_phases = json.loads(resp.choices[0].message.content)
            for k, v in new_phases.items():
                bp_data[k] = v
            return bp_data
        except Exception as e:
            st.error(f"éƒ¨åˆ†å†ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return bp_data

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”¥ HTMLè¡¨ç¤ºæ©Ÿèƒ½
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def convert_to_html_table(self, bp_data: Dict) -> str:
        """BPè¡¨ã®HTMLå¤‰æ›ï¼ˆæ¨ªé•·ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: ãƒ•ã‚§ãƒ¼ã‚ºã‚’åˆ—ã«é…ç½®ï¼‰"""
        if not bp_data:
            return "<p>âŒ BPè¡¨ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“</p>"
        
        phase_keys = ["phase_1", "phase_2", "phase_3", "phase_4", "phase_5", "phase_6", "phase_7"]
        field_labels = {
            'phase_name': 'ãƒ•ã‚§ãƒ¼ã‚ºå',
            'activities': 'ä¸»è¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£',
            'inputs': 'ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ',
            'outputs': 'ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆ',
            'tools': 'ä½¿ç”¨ãƒ„ãƒ¼ãƒ«',
            'stakeholders': 'ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼',
            'kpi': 'KPI',
            'risks': 'ãƒªã‚¹ã‚¯',
            'countermeasures': 'å¯¾ç­–'
        }
        
        html_output = """
<div style="overflow-x: auto;">
<table style="width: 100%; border-collapse: collapse; border: 1px solid #ddd; font-size: 13px;">
<thead style="background-color: #f4f4f4;">
<tr>
    <th style="border: 1px solid #ddd; padding: 6px; text-align: left; min-width: 120px; position: sticky; left: 0; background-color: #f4f4f4; z-index: 1;">é …ç›®</th>
"""
        
        # ãƒ•ã‚§ãƒ¼ã‚ºåˆ—ãƒ˜ãƒƒãƒ€ãƒ¼
        for pk in phase_keys:
            phase = bp_data.get(pk, {})
            phase_name = html_module.escape(str(phase.get('phase_name', pk)))
            html_output += f'    <th style="border: 1px solid #ddd; padding: 6px; text-align: left; min-width: 180px;">{phase_name}</th>\n'
        
        html_output += "</tr>\n</thead>\n<tbody>\n"
        
        # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¡Œã¨ã—ã¦è¡¨ç¤º
        for field_key, field_label in field_labels.items():
            if field_key == 'phase_name':
                continue  # phase_nameã¯åˆ—ãƒ˜ãƒƒãƒ€ãƒ¼ã§ä½¿ç”¨æ¸ˆã¿
            
            html_output += f'<tr>\n    <td style="border: 1px solid #ddd; padding: 6px; background-color: #f9f9f9; font-weight: bold; position: sticky; left: 0; z-index: 1;">{field_label}</td>\n'
            
            for pk in phase_keys:
                phase = bp_data.get(pk, {})
                value = html_module.escape(str(phase.get(field_key, '')))
                html_output += f'    <td style="border: 1px solid #ddd; padding: 6px; word-wrap: break-word;">{value}</td>\n'
            
            html_output += "</tr>\n"
        
        html_output += """
</tbody>
</table>
</div>
"""
        return html_output
    
    def convert_to_tsv(self, bp_data: Dict) -> str:
        """BPè¡¨ã®TSVå¤‰æ›ï¼ˆExcel/ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã‚³ãƒ”ãƒšç”¨ï¼‰"""
        if not bp_data:
            return "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        phase_keys = ["phase_1", "phase_2", "phase_3", "phase_4", "phase_5", "phase_6", "phase_7"]
        field_labels = {
            'phase_name': 'ãƒ•ã‚§ãƒ¼ã‚ºå',
            'activities': 'ä¸»è¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£',
            'inputs': 'ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ',
            'outputs': 'ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆ',
            'tools': 'ä½¿ç”¨ãƒ„ãƒ¼ãƒ«',
            'stakeholders': 'ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼',
            'kpi': 'KPI',
            'risks': 'ãƒªã‚¹ã‚¯',
            'countermeasures': 'å¯¾ç­–'
        }
        
        lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        header = ["é …ç›®"]
        for pk in phase_keys:
            phase = bp_data.get(pk, {})
            header.append(str(phase.get('phase_name', pk)))
        lines.append("\t".join(header))
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for field_key, field_label in field_labels.items():
            if field_key == 'phase_name':
                continue
            
            row = [field_label]
            for pk in phase_keys:
                phase = bp_data.get(pk, {})
                value = str(phase.get(field_key, '')).replace('\t', ' ').replace('\n', ' ')
                row.append(value)
            lines.append("\t".join(row))
        
        return "\n".join(lines)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Streamlit UI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    st.title("ğŸ”¥ è·ç¨®ç‰¹åŒ–BPå¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ  v5")
    st.markdown("""
    **v5ã®ç‰¹å¾´: æ¤œç´¢åŠ¹ç‡åŒ– Ã— å°‚é–€æ€§å¼·åŒ– Ã— UIæ”¹å–„**
    
    - ğŸ” æœ€å°Webæ¤œç´¢ + LLMçŸ¥è­˜è£œå®Œï¼ˆæ¤œç´¢å›æ•°80%å‰Šæ¸›ï¼‰
    - âš™ï¸ ãƒ•ã‚§ãƒ¼ã‚ºé©åˆæ€§ã‚¹ã‚³ã‚¢ã§å›ºæœ‰èªã‚’æœ€é©åˆ†æ•£
    - âœ… åŠ é‡ã‚«ãƒãƒ¬ãƒƒã‚¸0.50ç›®æ¨™ï¼ˆå¾“æ¥ã®2å€ï¼‰
    - ğŸ“Š æ¨ªé•·è¡¨ç¤º + ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚çµæœç¶­æŒ
    """)
    
    # APIè¨­å®š
    # --- APIã‚­ãƒ¼UIæœ€å°åŒ–: ä¸¡ã‚­ãƒ¼ãŒæ—¢ã«è¨­å®šæ¸ˆã¿ãªã‚‰UIã‚’éè¡¨ç¤º ---
    with st.sidebar:
        if not (st.session_state.get("openai_api_key") and st.session_state.get("serpapi_key")):
            st.header("ğŸ”‘ APIã‚­ãƒ¼è¨­å®š")
            if not st.session_state.get("openai_api_key"):
                input_openai = st.text_input("OpenAI API Key", value="", type="password")
                if input_openai:
                    st.session_state.openai_api_key = input_openai.strip()
            if not st.session_state.get("serpapi_key"):
                input_serp = st.text_input("SerpAPI Key", value="", type="password")
                if input_serp:
                    st.session_state.serpapi_key = input_serp.strip()
            if st.button("ğŸ”„ å†å…¥åŠ›/ã‚¯ãƒªã‚¢"):
                st.session_state.openai_api_key = ""
                st.session_state.serpapi_key = ""
                st.experimental_rerun()
            if not st.session_state.get('openai_api_key'):
                st.caption("âš ï¸ OpenAIã‚­ãƒ¼æœªè¨­å®š: ç”Ÿæˆä¸å¯")
            if not st.session_state.get('serpapi_key'):
                st.caption("â„¹ï¸ SerpAPIæœªè¨­å®š: å›ºæœ‰æŠ½å‡ºãŒè¡Œã‚ã‚Œãšä¸€èˆ¬è«–åŒ–ãƒªã‚¹ã‚¯")
    
    # è·ç¨®å…¥åŠ›
    col1, col2 = st.columns(2)
    
    with col1:
        industry = st.text_input(
            "ğŸ¢ æ¥­ç•Œå",
            value="è£½é€ æ¥­ï¼ˆEVï¼‰",
            help="ä¾‹: è£½é€ æ¥­ï¼ˆEVï¼‰, IT, é‡‘è, åŒ»ç™‚æ©Ÿå™¨"
        )
    
    with col2:
        job_title = st.text_input(
            "ğŸ‘¤ è·ç¨®å", 
            value="ææ–™é–‹ç™ºã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
            help="ä¾‹: ææ–™é–‹ç™ºã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢, AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢, ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"
        )
    
    if not industry or not job_title:
        st.warning("âš ï¸ æ¥­ç•Œåã¨è·ç¨®åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    analyzer = LayeredBPAnalyzer()
    
    # å‡¦ç†çŠ¶æ³ç®¡ç†
    if "current_layer" not in st.session_state:
        st.session_state.current_layer = 0
    if "job_info" not in st.session_state:
        st.session_state.job_info = {}
    if "bp_data" not in st.session_state:
        st.session_state.bp_data = {}
    
    # ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘ : è·ç¨®å›ºæœ‰æƒ…å ±æŠ½å‡º
    # v3äº’æ›: å˜ä¸€ãƒœã‚¿ãƒ³ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    st.markdown("---")
    if st.button("ğŸš€ è·ç¨®ç‰¹åŒ–BPè¡¨ã‚’ç”Ÿæˆ", type="primary"):
        if not industry or not job_title:
            st.error("æ¥­ç•Œåã¨è·ç¨®åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        if not st.session_state.get('openai_api_key'):
            st.error("OpenAI API Key ãŒæœªè¨­å®šã§ã™")
            return
        with st.spinner("Webæ¤œç´¢â†’å›ºæœ‰æŠ½å‡ºâ†’BPæ§‹ç¯‰â†’å›ºæœ‰æ€§ãƒã‚§ãƒƒã‚¯ å®Ÿè¡Œä¸­..."):
            # ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘ ï¼ˆSerpAPIã‚ã‚Œã°ï¼‰
            if st.session_state.get('serpapi_key'):
                job_info = analyzer.extract_job_specific_info(industry, job_title)
            else:
                job_info = {}
            st.session_state.job_info = job_info
            # ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¡
            if job_info:
                analyzer.job_specific_info = job_info
            bp_data = analyzer.generate_bp_with_job_info(industry, job_title) if job_info else {}
            st.session_state.bp_data = bp_data
            # ãƒ¬ã‚¤ãƒ¤ãƒ¼â‘¢
            if bp_data:
                analyzer.job_specific_info = job_info
                is_valid, errors, metrics = analyzer.validate_job_specificity(bp_data)
                st.session_state.validation_metrics = metrics
                st.session_state.validation_is_valid = is_valid
                st.session_state.validation_errors = errors
            else:
                st.session_state.validation_is_valid = False
                st.session_state.validation_errors = ["BPæœªç”Ÿæˆ"]
    
    # ğŸ”¥ çµæœè¡¨ç¤ºã‚’ãƒœã‚¿ãƒ³ã®å¤–ã«ç§»å‹•ï¼ˆå¸¸ã«è¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
    if st.session_state.get('job_info'):
        with st.expander("ğŸ“‹ æŠ½å‡ºã•ã‚ŒãŸè·ç¨®å›ºæœ‰æ§‹é€ ", expanded=True):
            st.json(st.session_state.job_info)
    
    if st.session_state.get('bp_data'):
        st.markdown("---")
        st.header("ğŸ“Š è·ç¨®ç‰¹åŒ–BPè¡¨")
        html_table = analyzer.convert_to_html_table(st.session_state.bp_data)
        st.markdown(html_table, unsafe_allow_html=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚³ãƒ”ãƒ¼æ©Ÿèƒ½ï¼ˆåˆæœŸåŒ–ã•ã‚Œãªã„ï¼‰
        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            json_str = json.dumps(st.session_state.bp_data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ’¾ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", 
                data=json_str, 
                file_name=f"bp_{industry}_{job_title}.json", 
                mime="application/json",
                key="download_json_btn"  # keyæŒ‡å®šã§åˆæœŸåŒ–é˜²æ­¢
            )
        with col_dl2:
            tsv_str = analyzer.convert_to_tsv(st.session_state.bp_data)
            st.download_button(
                label="ğŸ“‹ TSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆExcel/ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”¨ï¼‰",
                data=tsv_str,
                file_name=f"bp_{industry}_{job_title}.tsv",
                mime="text/tab-separated-values",
                key="download_tsv_btn"  # keyæŒ‡å®šã§åˆæœŸåŒ–é˜²æ­¢
            )
    
    # å›ºæœ‰æ€§çµæœè¡¨ç¤º
    if st.session_state.get('bp_data') and st.session_state.get('job_info'):
        is_valid = st.session_state.get('validation_is_valid', False)
        errors = st.session_state.get('validation_errors', [])
        
        if is_valid:
            st.success("ğŸ‰ å›ºæœ‰æ€§ãƒã‚§ãƒƒã‚¯åˆæ ¼")
        else:
            st.error("âŒ å›ºæœ‰æ€§ãƒã‚§ãƒƒã‚¯ä¸åˆæ ¼")
            for e in errors:
                st.error(e)
            missing_phases = (st.session_state.get('validation_metrics') or {}).get('phases_without_specificity', [])
            if missing_phases:
                if st.button("â™»ï¸ ä¸è¶³ãƒ•ã‚§ãƒ¼ã‚ºã®ã¿å†ç”Ÿæˆ", key="regenerate_btn"):
                    analyzer.job_specific_info = st.session_state.job_info
                    st.session_state.bp_data = analyzer.regenerate_missing_phases(
                        st.session_state.bp_data, 
                        missing_phases, 
                        industry, 
                        job_title
                    )
                    # å†è©•ä¾¡
                    is_valid2, errors2, metrics2 = analyzer.validate_job_specificity(st.session_state.bp_data)
                    st.session_state.validation_metrics = metrics2
                    st.session_state.validation_is_valid = is_valid2
                    st.session_state.validation_errors = errors2
                    if is_valid2:
                        st.success("âœ… å†ç”Ÿæˆå¾Œ åˆæ ¼")
                    else:
                        st.warning("å†ç”Ÿæˆå¾Œã‚‚ä¸åˆæ ¼")
                        for e2 in errors2:
                            st.warning(e2)
                    st.rerun()
    
    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ï¼ˆçµæœè¡¨ç¤ºãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    if st.session_state.get('bp_data') or st.session_state.get('job_info'):
        st.markdown("---")
        if st.button("ğŸ”„ å…¨ãƒªã‚»ãƒƒãƒˆ", key="reset"):
            st.session_state.current_layer = 0
            st.session_state.job_info = {}
            st.session_state.bp_data = {}
            st.session_state.validation_metrics = {}
            st.session_state.validation_is_valid = False
            st.session_state.validation_errors = []
            st.rerun()

    # è‡ªå‹•å®Ÿè¡Œæ©Ÿèƒ½ã¯v3äº’æ›åŒ–ã®ãŸã‚å‰Šé™¤æ¸ˆã¿

if __name__ == "__main__":
    main()